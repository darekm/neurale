{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import  GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import Conv2D,Flatten\n",
    "from keras.backend import argmax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "csv_url='mrec20190331sfft.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>training</th>\n",
       "      <th>step</th>\n",
       "      <th>up</th>\n",
       "      <th>slice</th>\n",
       "      <th>F_1</th>\n",
       "      <th>F_2</th>\n",
       "      <th>F_3</th>\n",
       "      <th>F_4</th>\n",
       "      <th>...</th>\n",
       "      <th>F_119</th>\n",
       "      <th>F_120</th>\n",
       "      <th>F_121</th>\n",
       "      <th>F_122</th>\n",
       "      <th>F_123</th>\n",
       "      <th>F_124</th>\n",
       "      <th>F_125</th>\n",
       "      <th>F_126</th>\n",
       "      <th>F_127</th>\n",
       "      <th>F_128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1554034538313</td>\n",
       "      <td>13:15:38.313</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20749</td>\n",
       "      <td>20.056</td>\n",
       "      <td>94.1213</td>\n",
       "      <td>56.6893</td>\n",
       "      <td>244.1506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>1.6455</td>\n",
       "      <td>1.2656</td>\n",
       "      <td>1.0433</td>\n",
       "      <td>1.3137</td>\n",
       "      <td>2.4414</td>\n",
       "      <td>1.0232</td>\n",
       "      <td>1.2927</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>1.7651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1554034538958</td>\n",
       "      <td>13:15:38.958</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11691</td>\n",
       "      <td>42.667</td>\n",
       "      <td>47.5442</td>\n",
       "      <td>72.8170</td>\n",
       "      <td>77.0697</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>1.0529</td>\n",
       "      <td>1.0475</td>\n",
       "      <td>1.0450</td>\n",
       "      <td>1.2355</td>\n",
       "      <td>1.4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1554034539517</td>\n",
       "      <td>13:15:39.517</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>16388</td>\n",
       "      <td>14.943</td>\n",
       "      <td>104.5249</td>\n",
       "      <td>123.5440</td>\n",
       "      <td>325.2235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4323</td>\n",
       "      <td>2.3395</td>\n",
       "      <td>1.9636</td>\n",
       "      <td>2.7001</td>\n",
       "      <td>1.6907</td>\n",
       "      <td>1.3859</td>\n",
       "      <td>1.2406</td>\n",
       "      <td>1.8272</td>\n",
       "      <td>2.2453</td>\n",
       "      <td>1.9073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1554034540279</td>\n",
       "      <td>13:15:40.279</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7260</td>\n",
       "      <td>67.612</td>\n",
       "      <td>65.4221</td>\n",
       "      <td>27.6171</td>\n",
       "      <td>155.5133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>1.1747</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.7708</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>0.8781</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.3874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1554034540774</td>\n",
       "      <td>13:15:40.774</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10254</td>\n",
       "      <td>51.408</td>\n",
       "      <td>151.3434</td>\n",
       "      <td>105.4404</td>\n",
       "      <td>376.3469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4306</td>\n",
       "      <td>1.2238</td>\n",
       "      <td>1.7379</td>\n",
       "      <td>0.3559</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>1.4681</td>\n",
       "      <td>0.6975</td>\n",
       "      <td>1.1393</td>\n",
       "      <td>1.1507</td>\n",
       "      <td>0.8577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1554034541375</td>\n",
       "      <td>13:15:41.375</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>12306</td>\n",
       "      <td>43.714</td>\n",
       "      <td>197.7310</td>\n",
       "      <td>287.9238</td>\n",
       "      <td>458.5304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.2905</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.8668</td>\n",
       "      <td>1.0058</td>\n",
       "      <td>0.3264</td>\n",
       "      <td>0.7247</td>\n",
       "      <td>0.2743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1554034542523</td>\n",
       "      <td>13:15:42.523</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>12275</td>\n",
       "      <td>36.233</td>\n",
       "      <td>4.3915</td>\n",
       "      <td>16.2003</td>\n",
       "      <td>67.3880</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1263</td>\n",
       "      <td>3.0966</td>\n",
       "      <td>0.7637</td>\n",
       "      <td>4.8209</td>\n",
       "      <td>2.8054</td>\n",
       "      <td>2.8560</td>\n",
       "      <td>6.5081</td>\n",
       "      <td>4.1053</td>\n",
       "      <td>4.8375</td>\n",
       "      <td>6.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1554034542921</td>\n",
       "      <td>13:15:42.921</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11018</td>\n",
       "      <td>8.626</td>\n",
       "      <td>32.5530</td>\n",
       "      <td>114.6319</td>\n",
       "      <td>209.5523</td>\n",
       "      <td>...</td>\n",
       "      <td>12.8564</td>\n",
       "      <td>10.8709</td>\n",
       "      <td>12.2103</td>\n",
       "      <td>5.6484</td>\n",
       "      <td>4.5759</td>\n",
       "      <td>3.3081</td>\n",
       "      <td>11.8470</td>\n",
       "      <td>11.5552</td>\n",
       "      <td>9.8679</td>\n",
       "      <td>11.1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1554034543324</td>\n",
       "      <td>13:15:43.324</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>48631</td>\n",
       "      <td>32.854</td>\n",
       "      <td>117.6710</td>\n",
       "      <td>414.5323</td>\n",
       "      <td>808.1890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7231</td>\n",
       "      <td>2.2230</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>1.8384</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>1.7533</td>\n",
       "      <td>0.5601</td>\n",
       "      <td>1.9654</td>\n",
       "      <td>1.1408</td>\n",
       "      <td>0.8986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1554034543872</td>\n",
       "      <td>13:15:43.872</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>12990</td>\n",
       "      <td>95.478</td>\n",
       "      <td>328.9371</td>\n",
       "      <td>369.8189</td>\n",
       "      <td>122.3947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1821</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>1.0916</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.7634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1554034552741</td>\n",
       "      <td>13:15:52.741</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7295</td>\n",
       "      <td>51.179</td>\n",
       "      <td>110.7519</td>\n",
       "      <td>121.1264</td>\n",
       "      <td>48.1045</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1168</td>\n",
       "      <td>1.2650</td>\n",
       "      <td>1.0660</td>\n",
       "      <td>0.5436</td>\n",
       "      <td>1.8927</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>1.9604</td>\n",
       "      <td>2.4926</td>\n",
       "      <td>2.0846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1554034553464</td>\n",
       "      <td>13:15:53.464</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15670</td>\n",
       "      <td>91.319</td>\n",
       "      <td>297.7418</td>\n",
       "      <td>238.2316</td>\n",
       "      <td>187.9039</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0638</td>\n",
       "      <td>2.1898</td>\n",
       "      <td>5.2268</td>\n",
       "      <td>3.8690</td>\n",
       "      <td>1.8847</td>\n",
       "      <td>4.5757</td>\n",
       "      <td>2.6038</td>\n",
       "      <td>3.7672</td>\n",
       "      <td>3.9683</td>\n",
       "      <td>2.8586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1554034554064</td>\n",
       "      <td>13:15:54.064</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7187</td>\n",
       "      <td>89.670</td>\n",
       "      <td>25.7131</td>\n",
       "      <td>114.5191</td>\n",
       "      <td>124.2920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6383</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>1.0036</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>1.8103</td>\n",
       "      <td>1.6553</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>0.3588</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.5634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1554034555772</td>\n",
       "      <td>13:15:55.772</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>63054</td>\n",
       "      <td>176.856</td>\n",
       "      <td>283.4218</td>\n",
       "      <td>629.3238</td>\n",
       "      <td>135.3471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4961</td>\n",
       "      <td>1.1693</td>\n",
       "      <td>1.2748</td>\n",
       "      <td>0.8044</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7229</td>\n",
       "      <td>1.1219</td>\n",
       "      <td>1.4850</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.9767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1554034556313</td>\n",
       "      <td>13:15:56.313</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7979</td>\n",
       "      <td>92.689</td>\n",
       "      <td>82.8024</td>\n",
       "      <td>227.5237</td>\n",
       "      <td>131.2919</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2423</td>\n",
       "      <td>7.1212</td>\n",
       "      <td>8.3202</td>\n",
       "      <td>2.1716</td>\n",
       "      <td>5.9391</td>\n",
       "      <td>6.3946</td>\n",
       "      <td>2.9856</td>\n",
       "      <td>4.9899</td>\n",
       "      <td>4.1904</td>\n",
       "      <td>3.5582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1554034556749</td>\n",
       "      <td>13:15:56.749</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9095</td>\n",
       "      <td>60.448</td>\n",
       "      <td>116.9732</td>\n",
       "      <td>83.3200</td>\n",
       "      <td>21.3689</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5014</td>\n",
       "      <td>2.7870</td>\n",
       "      <td>2.7309</td>\n",
       "      <td>1.7733</td>\n",
       "      <td>2.5238</td>\n",
       "      <td>1.4445</td>\n",
       "      <td>3.5992</td>\n",
       "      <td>1.5622</td>\n",
       "      <td>1.9059</td>\n",
       "      <td>1.0923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1554034557167</td>\n",
       "      <td>13:15:57.167</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10473</td>\n",
       "      <td>5.745</td>\n",
       "      <td>86.2626</td>\n",
       "      <td>214.0896</td>\n",
       "      <td>92.3728</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3324</td>\n",
       "      <td>5.7336</td>\n",
       "      <td>7.9026</td>\n",
       "      <td>9.3345</td>\n",
       "      <td>12.5422</td>\n",
       "      <td>9.1397</td>\n",
       "      <td>12.9683</td>\n",
       "      <td>10.5161</td>\n",
       "      <td>12.1184</td>\n",
       "      <td>8.5896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1554034557652</td>\n",
       "      <td>13:15:57.652</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9539</td>\n",
       "      <td>105.918</td>\n",
       "      <td>222.3163</td>\n",
       "      <td>146.9655</td>\n",
       "      <td>107.1227</td>\n",
       "      <td>...</td>\n",
       "      <td>23.9141</td>\n",
       "      <td>20.8094</td>\n",
       "      <td>6.7922</td>\n",
       "      <td>16.0169</td>\n",
       "      <td>20.7039</td>\n",
       "      <td>16.0992</td>\n",
       "      <td>14.9737</td>\n",
       "      <td>23.0030</td>\n",
       "      <td>20.7990</td>\n",
       "      <td>13.1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1554034558096</td>\n",
       "      <td>13:15:58.096</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>8128</td>\n",
       "      <td>113.464</td>\n",
       "      <td>202.6727</td>\n",
       "      <td>179.4488</td>\n",
       "      <td>142.2376</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3024</td>\n",
       "      <td>5.0787</td>\n",
       "      <td>5.5172</td>\n",
       "      <td>4.9711</td>\n",
       "      <td>3.8353</td>\n",
       "      <td>3.0314</td>\n",
       "      <td>3.4189</td>\n",
       "      <td>3.2492</td>\n",
       "      <td>1.4511</td>\n",
       "      <td>0.9276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1554034558486</td>\n",
       "      <td>13:15:58.486</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>8780</td>\n",
       "      <td>72.946</td>\n",
       "      <td>35.3417</td>\n",
       "      <td>163.8728</td>\n",
       "      <td>139.9921</td>\n",
       "      <td>...</td>\n",
       "      <td>19.7552</td>\n",
       "      <td>7.4400</td>\n",
       "      <td>12.9592</td>\n",
       "      <td>8.1229</td>\n",
       "      <td>18.1363</td>\n",
       "      <td>8.3398</td>\n",
       "      <td>11.5341</td>\n",
       "      <td>16.8605</td>\n",
       "      <td>8.9856</td>\n",
       "      <td>15.4814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1554034568646</td>\n",
       "      <td>13:16:08.646</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8535</td>\n",
       "      <td>39.649</td>\n",
       "      <td>54.2175</td>\n",
       "      <td>21.5935</td>\n",
       "      <td>108.3749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>1.4058</td>\n",
       "      <td>1.1511</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>1.3633</td>\n",
       "      <td>1.1481</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>1.3334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1554034569220</td>\n",
       "      <td>13:16:09.220</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13869</td>\n",
       "      <td>33.400</td>\n",
       "      <td>36.6111</td>\n",
       "      <td>34.0357</td>\n",
       "      <td>119.4974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1142</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.3173</td>\n",
       "      <td>0.3038</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.1936</td>\n",
       "      <td>0.7005</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>0.6733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1554034569985</td>\n",
       "      <td>13:16:09.985</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12336</td>\n",
       "      <td>53.202</td>\n",
       "      <td>15.5826</td>\n",
       "      <td>76.3712</td>\n",
       "      <td>129.6231</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1067</td>\n",
       "      <td>5.6749</td>\n",
       "      <td>1.3833</td>\n",
       "      <td>3.7632</td>\n",
       "      <td>4.2902</td>\n",
       "      <td>3.4170</td>\n",
       "      <td>2.1096</td>\n",
       "      <td>5.3670</td>\n",
       "      <td>2.9436</td>\n",
       "      <td>5.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1554034570413</td>\n",
       "      <td>13:16:10.413</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9037</td>\n",
       "      <td>78.870</td>\n",
       "      <td>53.4001</td>\n",
       "      <td>116.1074</td>\n",
       "      <td>411.5939</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9045</td>\n",
       "      <td>1.8140</td>\n",
       "      <td>1.5852</td>\n",
       "      <td>1.9278</td>\n",
       "      <td>1.9029</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.8157</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>0.7691</td>\n",
       "      <td>1.2878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time          date  training  step  up  slice      F_1       F_2  \\\n",
       "0   1554034538313  13:15:38.313         0     3   1  20749   20.056   94.1213   \n",
       "1   1554034538958  13:15:38.958         0     4   1  11691   42.667   47.5442   \n",
       "2   1554034539517  13:15:39.517         0     5   1  16388   14.943  104.5249   \n",
       "3   1554034540279  13:15:40.279         0     7   1   7260   67.612   65.4221   \n",
       "4   1554034540774  13:15:40.774         0     8   1  10254   51.408  151.3434   \n",
       "5   1554034541375  13:15:41.375         0     9   1  12306   43.714  197.7310   \n",
       "6   1554034542523  13:15:42.523         0    11   1  12275   36.233    4.3915   \n",
       "7   1554034542921  13:15:42.921         0    12   1  11018    8.626   32.5530   \n",
       "8   1554034543324  13:15:43.324         0    13   1  48631   32.854  117.6710   \n",
       "9   1554034543872  13:15:43.872         0    14   1  12990   95.478  328.9371   \n",
       "10  1554034552741  13:15:52.741         0     3   2   7295   51.179  110.7519   \n",
       "11  1554034553464  13:15:53.464         0     4   2  15670   91.319  297.7418   \n",
       "12  1554034554064  13:15:54.064         0     5   2   7187   89.670   25.7131   \n",
       "13  1554034555772  13:15:55.772         0     7   2  63054  176.856  283.4218   \n",
       "14  1554034556313  13:15:56.313         0     8   2   7979   92.689   82.8024   \n",
       "15  1554034556749  13:15:56.749         0     9   2   9095   60.448  116.9732   \n",
       "16  1554034557167  13:15:57.167         0    10   2  10473    5.745   86.2626   \n",
       "17  1554034557652  13:15:57.652         0    12   2   9539  105.918  222.3163   \n",
       "18  1554034558096  13:15:58.096         0    13   2   8128  113.464  202.6727   \n",
       "19  1554034558486  13:15:58.486         0    14   2   8780   72.946   35.3417   \n",
       "20  1554034568646  13:16:08.646         0     3   1   8535   39.649   54.2175   \n",
       "21  1554034569220  13:16:09.220         0     4   1  13869   33.400   36.6111   \n",
       "22  1554034569985  13:16:09.985         0     6   1  12336   53.202   15.5826   \n",
       "23  1554034570413  13:16:10.413         0     7   1   9037   78.870   53.4001   \n",
       "\n",
       "         F_3       F_4   ...       F_119    F_120    F_121    F_122    F_123  \\\n",
       "0    56.6893  244.1506   ...      0.9821   1.6455   1.2656   1.0433   1.3137   \n",
       "1    72.8170   77.0697   ...      1.0073   0.9375   0.8401   0.9308   0.8793   \n",
       "2   123.5440  325.2235   ...      0.4323   2.3395   1.9636   2.7001   1.6907   \n",
       "3    27.6171  155.5133   ...      0.7560   1.1747   0.5885   0.3979   0.7220   \n",
       "4   105.4404  376.3469   ...      0.4306   1.2238   1.7379   0.3559   0.4861   \n",
       "5   287.9238  458.5304   ...      0.1554   0.9977   0.3534   0.2905   0.0378   \n",
       "6    16.2003   67.3880   ...      1.1263   3.0966   0.7637   4.8209   2.8054   \n",
       "7   114.6319  209.5523   ...     12.8564  10.8709  12.2103   5.6484   4.5759   \n",
       "8   414.5323  808.1890   ...      0.7231   2.2230   0.1032   1.8384   0.9183   \n",
       "9   369.8189  122.3947   ...      0.1821   0.3310   0.1429   0.9825   0.4588   \n",
       "10  121.1264   48.1045   ...      1.1168   1.2650   1.0660   0.5436   1.8927   \n",
       "11  238.2316  187.9039   ...      6.0638   2.1898   5.2268   3.8690   1.8847   \n",
       "12  114.5191  124.2920   ...      0.6383   0.2362   1.0036   1.5005   1.8103   \n",
       "13  629.3238  135.3471   ...      1.4961   1.1693   1.2748   0.8044   0.6667   \n",
       "14  227.5237  131.2919   ...      2.2423   7.1212   8.3202   2.1716   5.9391   \n",
       "15   83.3200   21.3689   ...      2.5014   2.7870   2.7309   1.7733   2.5238   \n",
       "16  214.0896   92.3728   ...      7.3324   5.7336   7.9026   9.3345  12.5422   \n",
       "17  146.9655  107.1227   ...     23.9141  20.8094   6.7922  16.0169  20.7039   \n",
       "18  179.4488  142.2376   ...      4.3024   5.0787   5.5172   4.9711   3.8353   \n",
       "19  163.8728  139.9921   ...     19.7552   7.4400  12.9592   8.1229  18.1363   \n",
       "20   21.5935  108.3749   ...      0.8681   1.4058   1.1511   0.6821   0.3394   \n",
       "21   34.0357  119.4974   ...      0.1142   0.7304   0.9182   0.3173   0.3038   \n",
       "22   76.3712  129.6231   ...      3.1067   5.6749   1.3833   3.7632   4.2902   \n",
       "23  116.1074  411.5939   ...      1.9045   1.8140   1.5852   1.9278   1.9029   \n",
       "\n",
       "      F_124    F_125    F_126    F_127    F_128  \n",
       "0    2.4414   1.0232   1.2927   0.7879   1.7651  \n",
       "1    1.0529   1.0475   1.0450   1.2355   1.4466  \n",
       "2    1.3859   1.2406   1.8272   2.2453   1.9073  \n",
       "3    0.7708   0.3064   0.8781   0.7001   0.3874  \n",
       "4    1.4681   0.6975   1.1393   1.1507   0.8577  \n",
       "5    0.8668   1.0058   0.3264   0.7247   0.2743  \n",
       "6    2.8560   6.5081   4.1053   4.8375   6.3500  \n",
       "7    3.3081  11.8470  11.5552   9.8679  11.1101  \n",
       "8    1.7533   0.5601   1.9654   1.1408   0.8986  \n",
       "9    1.0916   0.6122   0.9901   0.4200   0.7634  \n",
       "10   0.9676   0.0917   1.9604   2.4926   2.0846  \n",
       "11   4.5757   2.6038   3.7672   3.9683   2.8586  \n",
       "12   1.6553   0.9874   0.3588   0.1287   0.5634  \n",
       "13   0.7229   1.1219   1.4850   0.7797   0.9767  \n",
       "14   6.3946   2.9856   4.9899   4.1904   3.5582  \n",
       "15   1.4445   3.5992   1.5622   1.9059   1.0923  \n",
       "16   9.1397  12.9683  10.5161  12.1184   8.5896  \n",
       "17  16.0992  14.9737  23.0030  20.7990  13.1253  \n",
       "18   3.0314   3.4189   3.2492   1.4511   0.9276  \n",
       "19   8.3398  11.5341  16.8605   8.9856  15.4814  \n",
       "20   1.3633   1.1481   0.7551   0.1447   1.3334  \n",
       "21   0.1145   0.1936   0.7005   0.6368   0.6733  \n",
       "22   3.4170   2.1096   5.3670   2.9436   5.0052  \n",
       "23   0.5600   0.8157   0.7449   0.7691   1.2878  \n",
       "\n",
       "[24 rows x 134 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MM= pandas.read_csv(csv_url)\n",
    "#Mdataset=shuffle(MM)\n",
    "Mdataset=MM\n",
    "#Mdataset=MM.sample(frac=1)\n",
    "Mdataset.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_1</th>\n",
       "      <th>F_2</th>\n",
       "      <th>F_3</th>\n",
       "      <th>F_4</th>\n",
       "      <th>F_5</th>\n",
       "      <th>F_6</th>\n",
       "      <th>F_7</th>\n",
       "      <th>F_8</th>\n",
       "      <th>F_9</th>\n",
       "      <th>F_10</th>\n",
       "      <th>...</th>\n",
       "      <th>F_119</th>\n",
       "      <th>F_120</th>\n",
       "      <th>F_121</th>\n",
       "      <th>F_122</th>\n",
       "      <th>F_123</th>\n",
       "      <th>F_124</th>\n",
       "      <th>F_125</th>\n",
       "      <th>F_126</th>\n",
       "      <th>F_127</th>\n",
       "      <th>F_128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.056</td>\n",
       "      <td>94.1213</td>\n",
       "      <td>56.6893</td>\n",
       "      <td>244.1506</td>\n",
       "      <td>297.1014</td>\n",
       "      <td>68.4912</td>\n",
       "      <td>73.1389</td>\n",
       "      <td>86.4008</td>\n",
       "      <td>46.9100</td>\n",
       "      <td>33.9853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>1.6455</td>\n",
       "      <td>1.2656</td>\n",
       "      <td>1.0433</td>\n",
       "      <td>1.3137</td>\n",
       "      <td>2.4414</td>\n",
       "      <td>1.0232</td>\n",
       "      <td>1.2927</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>1.7651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.667</td>\n",
       "      <td>47.5442</td>\n",
       "      <td>72.8170</td>\n",
       "      <td>77.0697</td>\n",
       "      <td>35.0869</td>\n",
       "      <td>51.4889</td>\n",
       "      <td>103.3456</td>\n",
       "      <td>73.5672</td>\n",
       "      <td>6.5732</td>\n",
       "      <td>18.0737</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>1.0529</td>\n",
       "      <td>1.0475</td>\n",
       "      <td>1.0450</td>\n",
       "      <td>1.2355</td>\n",
       "      <td>1.4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.943</td>\n",
       "      <td>104.5249</td>\n",
       "      <td>123.5440</td>\n",
       "      <td>325.2235</td>\n",
       "      <td>216.0460</td>\n",
       "      <td>188.1778</td>\n",
       "      <td>216.8083</td>\n",
       "      <td>106.9825</td>\n",
       "      <td>14.6230</td>\n",
       "      <td>98.7340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4323</td>\n",
       "      <td>2.3395</td>\n",
       "      <td>1.9636</td>\n",
       "      <td>2.7001</td>\n",
       "      <td>1.6907</td>\n",
       "      <td>1.3859</td>\n",
       "      <td>1.2406</td>\n",
       "      <td>1.8272</td>\n",
       "      <td>2.2453</td>\n",
       "      <td>1.9073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.612</td>\n",
       "      <td>65.4221</td>\n",
       "      <td>27.6171</td>\n",
       "      <td>155.5133</td>\n",
       "      <td>82.3221</td>\n",
       "      <td>36.4214</td>\n",
       "      <td>46.7972</td>\n",
       "      <td>11.0348</td>\n",
       "      <td>7.9684</td>\n",
       "      <td>6.5255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>1.1747</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.7708</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>0.8781</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.3874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      F_1       F_2       F_3       F_4       F_5       F_6       F_7  \\\n",
       "0  20.056   94.1213   56.6893  244.1506  297.1014   68.4912   73.1389   \n",
       "1  42.667   47.5442   72.8170   77.0697   35.0869   51.4889  103.3456   \n",
       "2  14.943  104.5249  123.5440  325.2235  216.0460  188.1778  216.8083   \n",
       "3  67.612   65.4221   27.6171  155.5133   82.3221   36.4214   46.7972   \n",
       "\n",
       "        F_8      F_9     F_10   ...     F_119   F_120   F_121   F_122   F_123  \\\n",
       "0   86.4008  46.9100  33.9853   ...    0.9821  1.6455  1.2656  1.0433  1.3137   \n",
       "1   73.5672   6.5732  18.0737   ...    1.0073  0.9375  0.8401  0.9308  0.8793   \n",
       "2  106.9825  14.6230  98.7340   ...    0.4323  2.3395  1.9636  2.7001  1.6907   \n",
       "3   11.0348   7.9684   6.5255   ...    0.7560  1.1747  0.5885  0.3979  0.7220   \n",
       "\n",
       "    F_124   F_125   F_126   F_127   F_128  \n",
       "0  2.4414  1.0232  1.2927  0.7879  1.7651  \n",
       "1  1.0529  1.0475  1.0450  1.2355  1.4466  \n",
       "2  1.3859  1.2406  1.8272  2.2453  1.9073  \n",
       "3  0.7708  0.3064  0.8781  0.7001  0.3874  \n",
       "\n",
       "[4 rows x 128 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdataset=Mdataset.iloc[:,6:]\n",
    "Xdataset.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    2\n",
       "11    2\n",
       "12    2\n",
       "13    2\n",
       "Name: up, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ydataset = Mdataset['up']\n",
    "Ydataset.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05107705, 0.13282973, 0.0315936 , 0.11904173, 0.41328094,\n",
       "       0.13013288, 0.06080097, 0.17240561, 0.11593018, 0.13377925,\n",
       "       0.16578296, 0.22347617, 0.18588993, 0.24958625, 0.24999181,\n",
       "       0.21088881, 0.25110176, 0.23986342, 0.18482355, 0.17883252,\n",
       "       0.08571672, 0.04426925, 0.07225791, 0.04398994, 0.04239361,\n",
       "       0.09207876, 0.02792083, 0.05240673, 0.03630493, 0.03536118,\n",
       "       0.03906149, 0.05114374, 0.31190407, 0.07596091, 0.0062227 ,\n",
       "       0.11509733, 0.05813498, 0.06469943, 0.03883907, 0.06532665,\n",
       "       0.08104072, 0.15104461, 0.02481355, 0.04821453, 0.03800076,\n",
       "       0.06716089, 0.03636204, 0.04252229, 0.02039525, 0.05664509,\n",
       "       0.08343108, 0.0506808 , 0.05086898, 0.10339523, 0.06999565,\n",
       "       0.10077718, 0.07215901, 0.05073296, 0.03928588, 0.08224652,\n",
       "       0.10731719, 0.07810754, 0.09611584, 0.06576441, 0.04820583,\n",
       "       0.01855257, 0.01783409, 0.0669564 , 0.05401583, 0.02569278,\n",
       "       0.0042775 , 0.02914104, 0.00444942, 0.01840004, 0.03252842,\n",
       "       0.01247216, 0.02284181, 0.01525286, 0.01313781, 0.00801906,\n",
       "       0.01558545, 0.01095846, 0.01185073, 0.00987019, 0.01022947,\n",
       "       0.00759526, 0.00351516, 0.00380238, 0.01086448, 0.00781609,\n",
       "       0.01839407, 0.02454824, 0.01837983, 0.01915168, 0.01719985,\n",
       "       0.01444853, 0.07601717, 0.00664145, 0.00400803, 0.02043834,\n",
       "       0.01854563, 0.00908576, 0.00544105, 0.01766119, 0.02045896,\n",
       "       0.01995918, 0.00327982, 0.00412347, 0.01148738, 0.00868088,\n",
       "       0.00191083, 0.00615714, 0.01725313, 0.01454628, 0.01727621,\n",
       "       0.01270132, 0.00898884, 0.02366211, 0.01558594, 0.02758063,\n",
       "       0.01705962, 0.01649737, 0.02054278, 0.04137462, 0.01304682,\n",
       "       0.01925503, 0.01511903, 0.02898126])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(Xdataset)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329, 1, 4, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05107705, 0.13282973, 0.0315936 , 0.11904173, 0.41328094,\n",
       "        0.13013288, 0.06080097, 0.17240561, 0.11593018, 0.13377925,\n",
       "        0.16578296, 0.22347617, 0.18588993, 0.24958625, 0.24999181,\n",
       "        0.21088881, 0.25110176, 0.23986342, 0.18482355, 0.17883252,\n",
       "        0.08571672, 0.04426925, 0.07225791, 0.04398994, 0.04239361,\n",
       "        0.09207876, 0.02792083, 0.05240673, 0.03630493, 0.03536118,\n",
       "        0.03906149, 0.05114374],\n",
       "       [0.31190407, 0.07596091, 0.0062227 , 0.11509733, 0.05813498,\n",
       "        0.06469943, 0.03883907, 0.06532665, 0.08104072, 0.15104461,\n",
       "        0.02481355, 0.04821453, 0.03800076, 0.06716089, 0.03636204,\n",
       "        0.04252229, 0.02039525, 0.05664509, 0.08343108, 0.0506808 ,\n",
       "        0.05086898, 0.10339523, 0.06999565, 0.10077718, 0.07215901,\n",
       "        0.05073296, 0.03928588, 0.08224652, 0.10731719, 0.07810754,\n",
       "        0.09611584, 0.06576441],\n",
       "       [0.04820583, 0.01855257, 0.01783409, 0.0669564 , 0.05401583,\n",
       "        0.02569278, 0.0042775 , 0.02914104, 0.00444942, 0.01840004,\n",
       "        0.03252842, 0.01247216, 0.02284181, 0.01525286, 0.01313781,\n",
       "        0.00801906, 0.01558545, 0.01095846, 0.01185073, 0.00987019,\n",
       "        0.01022947, 0.00759526, 0.00351516, 0.00380238, 0.01086448,\n",
       "        0.00781609, 0.01839407, 0.02454824, 0.01837983, 0.01915168,\n",
       "        0.01719985, 0.01444853],\n",
       "       [0.07601717, 0.00664145, 0.00400803, 0.02043834, 0.01854563,\n",
       "        0.00908576, 0.00544105, 0.01766119, 0.02045896, 0.01995918,\n",
       "        0.00327982, 0.00412347, 0.01148738, 0.00868088, 0.00191083,\n",
       "        0.00615714, 0.01725313, 0.01454628, 0.01727621, 0.01270132,\n",
       "        0.00898884, 0.02366211, 0.01558594, 0.02758063, 0.01705962,\n",
       "        0.01649737, 0.02054278, 0.04137462, 0.01304682, 0.01925503,\n",
       "        0.01511903, 0.02898126]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset=dataset.reshape((dataset.shape[0],1,-1))\n",
    "dataset=dataset.reshape(dataset.shape[0],1,4,32)\n",
    "print(dataset.shape)\n",
    "dataset[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286 43\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.87)\n",
    "test_size = len(dataset) - train_size\n",
    "trainX, testX = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(trainX), len(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_width = 48\n",
    "look_height=32\n",
    "from sklearn import preprocessing \n",
    "from sklearn import utils\n",
    "from io import StringIO\n",
    "\n",
    "#trainX, trainY = create_dataset(train, look_back)\n",
    "#testX, testY = create_dataset(test, look_back)\n",
    "le = preprocessing.LabelEncoder()\n",
    "YN=utils.column_or_1d(Ydataset, warn=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "YO=le.fit_transform(YN)\n",
    "YO\n",
    "len(le.classes_)\n",
    "Yclasses=len(le.classes_)\n",
    "print(Yclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 286 43\n"
     ]
    }
   ],
   "source": [
    "trainY = YO[0:train_size]\n",
    "testY=YO[train_size:len(YO)]\n",
    "print('data:',len(trainY), len(testY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 1, 4, 32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "#trainX = numpy.reshape(trainX, (trainX.shape[0],  trainX.shape[2],2))\n",
    "#testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286, 1, 4, 32)\n",
      "(286,)\n",
      "trainyo (286, 2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-82ee435ce46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainyo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainYO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "#dataset.shape\n",
    "print(trainY.shape)\n",
    "print('trainyo',trainYO.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_77 (Conv2D)           (None, 32, 30, 1)         416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 30, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 8, 28, 1)          776       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 8, 28, 1)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 450       \n",
      "=================================================================\n",
      "Total params: 1,642\n",
      "Trainable params: 1,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,1) , activation='relu', input_shape=(4,32,1)))\n",
    "model.add(MaxPooling2D(1))\n",
    "model.add(Conv2D(8, (3,1), activation='relu'))\n",
    "#model.add(MaxPooling1D(1))\n",
    "model.add(Dropout(0.1))\n",
    "#model.add(Dense(128))\n",
    "#model.add(Conv1D(128,1 ))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Conv1D(128,1 ))\n",
    "#model.add(MaxPooling1D())\n",
    "#model.add(Conv1D(128, 1, activation='relu'))\n",
    "#model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(Yclasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_77_input to have shape (4, 32, 1) but got array with shape (1, 4, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-9881e966a96a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#              metrics=['accuracy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainYO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_77_input to have shape (4, 32, 1) but got array with shape (1, 4, 32)"
     ]
    }
   ],
   "source": [
    "trainYO = to_categorical(trainY, num_classes=Yclasses)\n",
    "testYO = to_categorical(testY, num_classes=Yclasses)\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model.fit(trainX, trainYO, epochs=170)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trainYO = to_categorical(trainY, num_classes=Yclasses)\n",
    "testYO = to_categorical(testY, num_classes=Yclasses)\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(trainX, trainYO, epochs=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The model needs to be compiled before being used.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-041edf33f8bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestYO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \"\"\"\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m             raise RuntimeError('The model needs to be compiled '\n\u001b[0m\u001b[1;32m   1038\u001b[0m                                'before being used.')\n\u001b[1;32m   1039\u001b[0m         return self.model.evaluate(x, y,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The model needs to be compiled before being used."
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testX, testYO)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 0s 182us/step\n",
      "Test loss: 0.151658737888703\n",
      "Test accuracy: 0.9650349654517807\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(trainX, trainYO, verbose=1)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534883722316387\n",
      "0.965034965034965\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Keras reported accuracy:\n",
    "score = model.evaluate(testX,testYO, verbose=0) \n",
    "print(score[1])\n",
    "# 0.98580000000000001\n",
    "\n",
    "# Actual accuracy calculated manually:\n",
    "predY= model.predict(trainX)\n",
    "acc = sum([numpy.argmax(trainYO[i])==numpy.argmax(predY[i]) for i in range(len(trainYO))])/len(trainYO)\n",
    "print(acc)\n",
    "# 0.98580000000000001\n",
    "\n",
    "print(score[1]==acc)\n",
    "# True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict1 = model.predict(trainX)\n",
    "testPredict1 = model.predict(testX)\n",
    "#trainPredict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax(trainPredict)\n",
    "trainPredict=numpy.argmax(trainPredict1,1)\n",
    "testPredict=numpy.argmax(testPredict1,1)\n",
    "diffY=testPredict-testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(diffY)\n",
    "plt.plot(testY)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# invert predictions\n",
    "#trainPredict = scaler.inverse_transform(trainPredict)\n",
    "#trainY = scaler.inverse_transform([trainY])\n",
    "#testPredict = scaler.inverse_transform(testPredict)\n",
    "#testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 5.460 RMSE\n",
      "Test Score: 5.301 RMSE\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "print('Train Score: %.3f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "print('Test Score: %.3f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578, 256, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'look_back' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-44853d77e2ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainPredictPlot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainPredictPlot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainPredictPlot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainPredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainPredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# shift test predictions for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtestPredictPlot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'look_back' is not defined"
     ]
    }
   ],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "print(trainPredictPlot.shape)\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, 0] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)-7:len(dataset)-9, 0] = testPredict\n",
    "# plot baseline and predictions\n",
    "#plt.plot(scaler.inverse_transform(dataset),label=\"set\")\n",
    "plt.plot(trainPredictPlot,label=\"train\")\n",
    "plt.plot(testPredictPlot,label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (387) into shape (387,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-2d6065407b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainPredictPlot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainPredictPlot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwws\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainPredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwws\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainPredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mwws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# shift test predictions for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (387) into shape (387,1)"
     ]
    }
   ],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "wws=2;\n",
    "trainPredictPlot[wws:len(trainPredict)+wws,0] = trainPredict\n",
    "wws=60\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+wws+1:len(dataset)-look_back-1, 0] = testPredict\n",
    "# plot baseline and predictions\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(trainY,label=\"set\")\n",
    "ax1.plot(trainPredictPlot,label=\"train\")\n",
    "ax2.plot(testPredictPlot,label=\"testm\")\n",
    "#plt.figure(figsize=(15,3))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
