{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D,ConvLSTM2D\n",
    "\n",
    "from tensorflow.keras.backend import argmax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataY.append(dataset[i + look_back, 0]) \n",
    "        dataX.append(a)\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resultset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        dataY.append(dataset.iloc[i + look_back, 0]) \n",
    "    return  numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MM (4030, 1)\n",
      "YPRED: (4030, 1)\n"
     ]
    }
   ],
   "source": [
    "import datasets \n",
    "from datasets import load_ypred, load_usps, load_mrec\n",
    "\n",
    "Y=load_ypred()\n",
    "\n",
    "#Y.shape\n",
    "Ysize=len(numpy.bincount(Y.iloc[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([219, 491, 466, 208, 378, 268, 298,  82,  64, 448, 128, 240, 152,\n",
       "       266, 196, 126])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 0.999))\n",
    "YM = scaler.fit_transform(Y)\n",
    "#YM=Y.loc[:,:]\n",
    "#YM\n",
    "\n",
    "numpy.bincount(Y.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "look_back = 20\n",
    "trainX, _ = create_dataset(YM, look_back)\n",
    "trainY =create_resultset(Y,look_back)\n",
    "Ysize=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[1:6]\n",
    "trainYO = to_categorical(trainY, num_classes=Ysize)\n",
    "trainYO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5994, 0.1332, 0.7992, 0.3996, 0.8658, 0.5994, 0.1332, 0.7992,\n",
       "        0.5994, 0.1332, 0.7992, 0.3996, 0.8658, 0.5994, 0.1332, 0.7992,\n",
       "        0.5994, 0.1332, 0.666 , 0.999 ],\n",
       "       [0.1332, 0.7992, 0.3996, 0.8658, 0.5994, 0.1332, 0.7992, 0.5994,\n",
       "        0.1332, 0.7992, 0.3996, 0.8658, 0.5994, 0.1332, 0.7992, 0.5994,\n",
       "        0.1332, 0.666 , 0.999 , 0.8658],\n",
       "       [0.7992, 0.3996, 0.8658, 0.5994, 0.1332, 0.7992, 0.5994, 0.1332,\n",
       "        0.7992, 0.3996, 0.8658, 0.5994, 0.1332, 0.7992, 0.5994, 0.1332,\n",
       "        0.666 , 0.999 , 0.8658, 0.5994],\n",
       "       [0.3996, 0.8658, 0.5994, 0.1332, 0.7992, 0.5994, 0.1332, 0.7992,\n",
       "        0.3996, 0.8658, 0.5994, 0.1332, 0.7992, 0.5994, 0.1332, 0.666 ,\n",
       "        0.999 , 0.8658, 0.5994, 0.1332],\n",
       "       [0.8658, 0.5994, 0.1332, 0.7992, 0.5994, 0.1332, 0.7992, 0.3996,\n",
       "        0.8658, 0.5994, 0.1332, 0.7992, 0.5994, 0.1332, 0.666 , 0.999 ,\n",
       "        0.8658, 0.5994, 0.1332, 0.7992]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4009, 1, 20)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "trainX.shape\n",
    "#testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le = preprocessing.LabelEncoder()\n",
    "#YN=utils.column_or_1d(Ydataset, warn=True)\n",
    "#YO=le.fit_transform(trainY)\n",
    "#YO\n",
    "\n",
    "maxTokens=13\n",
    "EMBEDDING_DIM = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 13  9 ...  2  1  9]\n"
     ]
    }
   ],
   "source": [
    "trainX[1:7,:]\n",
    "print(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainYO = to_categorical(trainY, num_classes=Ysize)\n",
    "trainYO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "unified_lstm_17 (UnifiedLSTM (None, 1, 40)             9760      \n",
      "_________________________________________________________________\n",
      "unified_lstm_18 (UnifiedLSTM (None, 16)                3648      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                272       \n",
      "=================================================================\n",
      "Total params: 13,680\n",
      "Trainable params: 13,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "#https://github.com/ar-ms/lstm-mnist/blob/master/lstm_classifier.py\n",
    "model = Sequential()\n",
    "#model.add(ConvLSTM2D(32,(3,1) , activation='relu', input_shape=(None,None,look_back,1)))\n",
    "model.add(LSTM(40,  input_shape=(1, look_back), return_sequences=True))\n",
    "model.add(LSTM(16))\n",
    "#model.add(Dense(30,activation=\"relu\",input_dim=30))\n",
    "model.add(Dropout(0.02))\n",
    "#model.add(Dense(30,activation=\"relu\"))\n",
    "model.add(Dense(Ysize,activation=\"softmax\"))\n",
    "#model.add(Dense(32, input_shape=(20,)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dense(25, activation='relu'))\n",
    "#model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "model.compile(loss='categorical_crossentropy',      optimizer='adam',     metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3608 samples, validate on 401 samples\n",
      "Epoch 1/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.5906 - accuracy: 0.8434 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
      "Epoch 2/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5804 - accuracy: 0.8489 - val_loss: 0.0591 - val_accuracy: 1.0000\n",
      "Epoch 3/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5784 - accuracy: 0.8484 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 4/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5711 - accuracy: 0.8484 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5697 - accuracy: 0.8517 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5599 - accuracy: 0.8548 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.5601 - accuracy: 0.8528 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5563 - accuracy: 0.8514 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.5478 - accuracy: 0.8539 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5428 - accuracy: 0.8578 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5422 - accuracy: 0.8564 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5322 - accuracy: 0.8592 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5334 - accuracy: 0.8620 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5271 - accuracy: 0.8631 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5249 - accuracy: 0.8625 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5186 - accuracy: 0.8653 - val_loss: 0.0441 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5141 - accuracy: 0.8670 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.5114 - accuracy: 0.8647 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.5095 - accuracy: 0.8631 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5038 - accuracy: 0.8731 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4952 - accuracy: 0.8689 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4948 - accuracy: 0.8711 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4951 - accuracy: 0.8672 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4882 - accuracy: 0.8672 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4822 - accuracy: 0.8717 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4817 - accuracy: 0.8706 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4771 - accuracy: 0.8758 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.4747 - accuracy: 0.8747 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4739 - accuracy: 0.8767 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4676 - accuracy: 0.8753 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4705 - accuracy: 0.8736 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4585 - accuracy: 0.8794 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4572 - accuracy: 0.8764 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4563 - accuracy: 0.8805 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4510 - accuracy: 0.8786 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.4429 - accuracy: 0.8853 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4499 - accuracy: 0.8780 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4419 - accuracy: 0.8805 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.4393 - accuracy: 0.8858 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4401 - accuracy: 0.8803 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.4338 - accuracy: 0.8836 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4289 - accuracy: 0.8844 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "3608/3608 [==============================] - 0s 52us/sample - loss: 0.4237 - accuracy: 0.8858 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4263 - accuracy: 0.8875 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4239 - accuracy: 0.8836 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4158 - accuracy: 0.8861 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4193 - accuracy: 0.8833 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4098 - accuracy: 0.8905 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4080 - accuracy: 0.8858 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3991 - accuracy: 0.8919 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "3608/3608 [==============================] - 0s 52us/sample - loss: 0.4084 - accuracy: 0.8908 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3963 - accuracy: 0.8919 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.4019 - accuracy: 0.8894 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3985 - accuracy: 0.8933 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3907 - accuracy: 0.8916 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.3947 - accuracy: 0.8961 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3930 - accuracy: 0.8925 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3888 - accuracy: 0.8911 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3843 - accuracy: 0.8947 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3837 - accuracy: 0.8927 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.3788 - accuracy: 0.8952 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.3787 - accuracy: 0.8963 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3739 - accuracy: 0.8944 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3724 - accuracy: 0.8988 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3734 - accuracy: 0.8925 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "3608/3608 [==============================] - 0s 50us/sample - loss: 0.3699 - accuracy: 0.8933 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3631 - accuracy: 0.8983 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3653 - accuracy: 0.8988 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3617 - accuracy: 0.8972 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.3620 - accuracy: 0.8977 - val_loss: 0.0203 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7fdd121198>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "### Train the residual compressor\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1) \n",
    "checkpointer = ModelCheckpoint('VSB_classifier', verbose=1, save_best_only=True)\n",
    "#results = class_model.fit(X, y, validation_split=0.2, batch_size=50, epochs=300, \n",
    "#                    callbacks=[earlystopper, checkpointer])\n",
    "#model.fit(trainX, trainYO, epochs=10, batch_size=1, verbose=2,validation_split=0.1,callbacks=[earlystopper, checkpointer])\n",
    "model.fit(trainX,trainYO,epochs=70,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4009, 16)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainYO.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn=model.predict(trainX[1:30])\n",
    "print('ll')\n",
    "nn2=numpy.argmax(nn,1)\n",
    "print(nn2)\n",
    "print(trainY[1:30])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#nn=model.predict(trainX)\n",
    "#print(nn.shape)\n",
    "print('oo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(trainX, trainY, verbose=1)\n",
    "\n",
    "print('Test loss:', score)\n",
    "#print('Test accuracy:', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
