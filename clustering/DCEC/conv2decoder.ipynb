{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,ConvLSTM2D,Conv1D\n",
    "\n",
    "from tensorflow.keras.backend import argmax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataY.append(dataset[i + look_back, 0]) \n",
    "        dataX.append(a)\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resultset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        dataY.append(dataset.iloc[i + look_back, 0]) \n",
    "    return  numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MM (4030, 1)\n",
      "YPRED: (4030, 1)\n"
     ]
    }
   ],
   "source": [
    "import datasets \n",
    "from datasets import load_ypred, load_usps, load_mrec\n",
    "\n",
    "Y=load_ypred()\n",
    "\n",
    "#Y.shape\n",
    "Ysize=len(numpy.bincount(Y.iloc[:,0]))\n",
    "Ysine=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([219, 491, 466, 208, 378, 268, 298,  82,  64, 448, 128, 240, 152,\n",
       "       266, 196, 126])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 0.999))\n",
    "YM = scaler.fit_transform(Y)\n",
    "#YM=Y.loc[:,:]\n",
    "#YM\n",
    "\n",
    "numpy.bincount(Y.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 20\n",
    "trainX, _ = create_dataset(YM, look_back)\n",
    "trainY =create_resultset(Y,look_back)\n",
    "Ysize=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4009, 20, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1],1))\n",
    "trainX.shape\n",
    "\n",
    "#testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 16, 120)           720       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 16, 120)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 15, 20)            4820      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 15, 20)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                4816      \n",
      "=================================================================\n",
      "Total params: 10,356\n",
      "Trainable params: 10,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(120,5 , activation='relu', input_shape=(look_back,1)))\n",
    "model.add(MaxPooling1D(1))\n",
    "model.add(Conv1D(20, 2, activation='relu'))\n",
    "#model.add(MaxPooling1D(1))\n",
    "model.add(Dropout(0.01))\n",
    "#model.add(Dense(128))\n",
    "#model.add(Conv1D(128,1 ))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Conv1D(128,1 ))\n",
    "#model.add(MaxPooling1D())\n",
    "#model.add(Conv1D(128, 1, activation='relu'))\n",
    "#model.add(GlobalAveragePooling1D())\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(Ysize, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainYO = to_categorical(trainY, num_classes=Ysize)\n",
    "trainYO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3608 samples, validate on 401 samples\n",
      "Epoch 1/70\n",
      "3608/3608 [==============================] - 0s 102us/sample - loss: 2.3093 - accuracy: 0.2866 - val_loss: 0.7290 - val_accuracy: 0.8753\n",
      "Epoch 2/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 1.8447 - accuracy: 0.4254 - val_loss: 0.5215 - val_accuracy: 1.0000\n",
      "Epoch 3/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 1.6633 - accuracy: 0.4956 - val_loss: 0.3025 - val_accuracy: 1.0000\n",
      "Epoch 4/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 1.5154 - accuracy: 0.5452 - val_loss: 0.3322 - val_accuracy: 1.0000\n",
      "Epoch 5/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 1.3973 - accuracy: 0.5876 - val_loss: 0.2878 - val_accuracy: 1.0000\n",
      "Epoch 6/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 1.2993 - accuracy: 0.6222 - val_loss: 0.2558 - val_accuracy: 1.0000\n",
      "Epoch 7/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 1.2030 - accuracy: 0.6635 - val_loss: 0.1786 - val_accuracy: 1.0000\n",
      "Epoch 8/70\n",
      "3608/3608 [==============================] - 0s 49us/sample - loss: 1.1068 - accuracy: 0.6929 - val_loss: 0.1813 - val_accuracy: 1.0000\n",
      "Epoch 9/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 1.0265 - accuracy: 0.7231 - val_loss: 0.1368 - val_accuracy: 1.0000\n",
      "Epoch 10/70\n",
      "3608/3608 [==============================] - 0s 52us/sample - loss: 0.9485 - accuracy: 0.7411 - val_loss: 0.1226 - val_accuracy: 1.0000\n",
      "Epoch 11/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.8774 - accuracy: 0.7716 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
      "Epoch 12/70\n",
      "3608/3608 [==============================] - 0s 52us/sample - loss: 0.8129 - accuracy: 0.7805 - val_loss: 0.1326 - val_accuracy: 1.0000\n",
      "Epoch 13/70\n",
      "3608/3608 [==============================] - 0s 53us/sample - loss: 0.7640 - accuracy: 0.7974 - val_loss: 0.0913 - val_accuracy: 1.0000\n",
      "Epoch 14/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.7032 - accuracy: 0.8082 - val_loss: 0.0900 - val_accuracy: 1.0000\n",
      "Epoch 15/70\n",
      "3608/3608 [==============================] - 0s 55us/sample - loss: 0.6562 - accuracy: 0.8210 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
      "Epoch 16/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.6229 - accuracy: 0.8304 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 17/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5797 - accuracy: 0.8376 - val_loss: 0.0688 - val_accuracy: 1.0000\n",
      "Epoch 18/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5479 - accuracy: 0.8451 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
      "Epoch 19/70\n",
      "3608/3608 [==============================] - 0s 51us/sample - loss: 0.5131 - accuracy: 0.8589 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 20/70\n",
      "3608/3608 [==============================] - 0s 55us/sample - loss: 0.4907 - accuracy: 0.8625 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 21/70\n",
      "3608/3608 [==============================] - 0s 55us/sample - loss: 0.4714 - accuracy: 0.8686 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 22/70\n",
      "3608/3608 [==============================] - 0s 55us/sample - loss: 0.4512 - accuracy: 0.8706 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 23/70\n",
      "3608/3608 [==============================] - 0s 55us/sample - loss: 0.4263 - accuracy: 0.8761 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 24/70\n",
      "3608/3608 [==============================] - 0s 55us/sample - loss: 0.4141 - accuracy: 0.8819 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 25/70\n",
      "3608/3608 [==============================] - 0s 56us/sample - loss: 0.3896 - accuracy: 0.8853 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 26/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.3773 - accuracy: 0.8880 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 27/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.3730 - accuracy: 0.8900 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 28/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.3545 - accuracy: 0.8936 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 29/70\n",
      "3608/3608 [==============================] - 0s 76us/sample - loss: 0.3460 - accuracy: 0.8972 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 30/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.3241 - accuracy: 0.9027 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 31/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.3152 - accuracy: 0.9055 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 32/70\n",
      "3608/3608 [==============================] - 0s 76us/sample - loss: 0.3115 - accuracy: 0.9005 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 33/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.3056 - accuracy: 0.9049 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 34/70\n",
      "3608/3608 [==============================] - 0s 76us/sample - loss: 0.2953 - accuracy: 0.9096 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 35/70\n",
      "3608/3608 [==============================] - 0s 74us/sample - loss: 0.2807 - accuracy: 0.9132 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 36/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.2756 - accuracy: 0.9124 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 37/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.2710 - accuracy: 0.9113 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 38/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.2655 - accuracy: 0.9157 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 39/70\n",
      "3608/3608 [==============================] - 0s 76us/sample - loss: 0.2579 - accuracy: 0.9199 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 40/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.2510 - accuracy: 0.9229 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 41/70\n",
      "3608/3608 [==============================] - 0s 76us/sample - loss: 0.2458 - accuracy: 0.9235 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 42/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.2397 - accuracy: 0.9213 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 43/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.2377 - accuracy: 0.9241 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 44/70\n",
      "3608/3608 [==============================] - 0s 75us/sample - loss: 0.2285 - accuracy: 0.9254 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 45/70\n",
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.2209 - accuracy: 0.9335 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 46/70\n",
      "3608/3608 [==============================] - 0s 84us/sample - loss: 0.2204 - accuracy: 0.9326 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 47/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.2152 - accuracy: 0.9321 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 48/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.2141 - accuracy: 0.9288 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 49/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.2124 - accuracy: 0.9318 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 50/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.2021 - accuracy: 0.9326 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 51/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.2005 - accuracy: 0.9379 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 52/70\n",
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.1993 - accuracy: 0.9360 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 53/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.1928 - accuracy: 0.9410 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 54/70\n",
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.1925 - accuracy: 0.9376 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 55/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.1937 - accuracy: 0.9346 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 56/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.1869 - accuracy: 0.9399 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 57/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.1881 - accuracy: 0.9371 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 58/70\n",
      "3608/3608 [==============================] - 0s 87us/sample - loss: 0.1770 - accuracy: 0.9412 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 59/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.1737 - accuracy: 0.9401 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 60/70\n",
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.1820 - accuracy: 0.9382 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 61/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.1729 - accuracy: 0.9424 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 62/70\n",
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.1681 - accuracy: 0.9446 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 63/70\n",
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.1619 - accuracy: 0.9473 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 64/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.1587 - accuracy: 0.9493 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 65/70\n",
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.1656 - accuracy: 0.9446 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 66/70\n",
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.1656 - accuracy: 0.9454 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 67/70\n",
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.1612 - accuracy: 0.9460 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 68/70\n",
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.1545 - accuracy: 0.9482 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 69/70\n",
      "3608/3608 [==============================] - 0s 86us/sample - loss: 0.1608 - accuracy: 0.9410 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 70/70\n",
      "3608/3608 [==============================] - 0s 85us/sample - loss: 0.1533 - accuracy: 0.9465 - val_loss: 0.0102 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3f7ccde80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(trainX, trainYO, epochs=70,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll [[4.64789046e-05 1.27639040e-01 1.01697037e-03 7.79515680e-14\n",
      "  3.54250398e-04 9.94177535e-04 2.15455401e-03 2.10913640e-06\n",
      "  1.54945269e-07 7.37730659e-07 2.88686570e-05 5.56765609e-17\n",
      "  1.60258524e-02 8.51084054e-01 3.92470356e-05 6.13519282e-04]\n",
      " [4.99964245e-02 3.78726693e-14 1.57194881e-06 9.21752317e-21\n",
      "  3.63504732e-05 1.03601838e-08 1.01050839e-03 1.55618356e-03\n",
      "  3.21657353e-06 9.44499373e-01 6.39095379e-05 2.87898911e-05\n",
      "  6.57187002e-07 2.36565247e-03 3.87233342e-07 4.37006587e-04]\n",
      " [7.75541703e-04 8.57356135e-05 9.98414636e-01 4.57845408e-06\n",
      "  3.61598999e-04 3.29468778e-04 1.60045802e-05 2.89503149e-23\n",
      "  4.39330461e-19 4.79616954e-12 1.34675054e-24 5.68114933e-09\n",
      "  3.20404638e-06 4.67437440e-06 6.65284782e-18 4.65360699e-06]\n",
      " [5.97485632e-06 1.43172871e-03 9.72558837e-03 2.32251679e-07\n",
      "  1.72865798e-03 2.22913150e-05 5.26649784e-03 1.22006040e-03\n",
      "  4.15046024e-08 2.02487674e-04 4.32640547e-03 2.56399856e-19\n",
      "  9.63680804e-01 1.23628890e-02 1.21503726e-05 1.41252376e-05]\n",
      " [9.41874236e-02 2.00731706e-12 1.19459519e-05 1.02528175e-13\n",
      "  3.33153323e-04 3.52413976e-04 5.96884498e-03 9.35192853e-02\n",
      "  6.29321657e-05 5.62045395e-01 5.93658595e-04 7.36543536e-02\n",
      "  2.31900488e-11 5.64718619e-03 1.31458932e-04 1.63491964e-01]\n",
      " [1.59541105e-06 3.54927724e-05 9.99558508e-01 1.44383405e-09\n",
      "  3.76845361e-04 7.99066527e-07 8.23567081e-09 4.53537061e-22\n",
      "  2.57869668e-18 1.77994815e-16 3.24102617e-28 1.17100663e-09\n",
      "  1.57067495e-06 2.50290268e-05 4.21249999e-18 1.16643697e-07]\n",
      " [5.24077450e-07 3.54071915e-07 1.64166444e-10 7.61239813e-13\n",
      "  2.53873604e-05 6.13905859e-09 2.98712735e-06 4.16133162e-06\n",
      "  2.21392042e-08 2.40949657e-06 9.95430589e-01 1.50931812e-13\n",
      "  4.38108062e-03 2.92343572e-07 1.10496838e-08 1.52266366e-04]\n",
      " [9.35375690e-01 1.21527635e-10 1.24229800e-05 3.27539329e-10\n",
      "  1.17115846e-07 3.32280729e-06 2.28105491e-04 1.53208788e-08\n",
      "  5.54303733e-05 7.91727507e-05 2.91445268e-09 5.48087619e-03\n",
      "  5.36696187e-10 1.07794739e-02 5.44805223e-09 4.79854532e-02]\n",
      " [1.31693414e-05 3.43521088e-02 2.65658274e-02 1.92833893e-16\n",
      "  1.72199736e-06 7.78445319e-05 7.24031343e-05 9.80476500e-08\n",
      "  2.01869327e-07 1.26985751e-05 1.78559771e-04 1.62049499e-16\n",
      "  1.79669894e-02 9.20752525e-01 4.86083536e-06 9.79553647e-07]\n",
      " [1.16233956e-02 1.26688712e-11 1.62083023e-08 7.25164767e-21\n",
      "  8.02380242e-08 1.62697216e-08 6.81206802e-05 6.69809338e-03\n",
      "  4.32062780e-06 9.78110254e-01 3.42164864e-03 1.69451323e-05\n",
      "  1.72069085e-05 1.49056814e-06 8.48673437e-07 3.75681484e-05]\n",
      " [1.86779129e-04 1.18182925e-06 9.99774873e-01 2.03862616e-08\n",
      "  4.57512179e-08 3.78136292e-06 2.28559305e-08 3.41288098e-25\n",
      "  9.64587823e-19 1.21431892e-11 2.36981997e-26 9.89355039e-12\n",
      "  3.57797525e-08 1.10024727e-08 4.19558411e-22 3.33125899e-05]\n",
      " [1.19557080e-06 9.86543298e-01 4.58509385e-06 2.15595386e-09\n",
      "  3.31517936e-06 1.12862317e-07 2.57675019e-08 1.00239902e-06\n",
      "  8.63846772e-11 2.60829693e-05 4.22143983e-03 1.71442711e-16\n",
      "  5.80539042e-03 3.35544650e-03 3.51261988e-05 2.98394752e-06]\n",
      " [4.22645845e-02 4.79545109e-16 4.38188363e-05 3.48942253e-15\n",
      "  7.25281552e-07 4.94824562e-05 6.32939773e-05 6.90964935e-03\n",
      "  5.95570309e-05 7.20228612e-01 8.15463252e-08 1.28706323e-03\n",
      "  1.65762279e-10 8.70616759e-07 4.46463027e-08 2.29092211e-01]\n",
      " [6.95477070e-07 4.11593704e-04 9.99400496e-01 8.39277536e-09\n",
      "  4.84321163e-07 9.17459511e-06 9.92686378e-09 3.52920271e-25\n",
      "  4.34049585e-18 1.33392822e-13 2.52041986e-24 3.09691422e-12\n",
      "  1.59291056e-04 1.82383628e-05 2.85124572e-14 6.56311201e-08]\n",
      " [2.31489597e-04 5.21547634e-07 4.01986108e-06 4.28592107e-15\n",
      "  2.45786741e-05 8.38836769e-08 1.22146330e-05 5.93113100e-06\n",
      "  5.30744728e-04 1.93392516e-05 9.90374327e-01 2.68153340e-08\n",
      "  7.68523291e-03 8.53523090e-07 4.35549964e-11 1.11076655e-03]\n",
      " [9.99891520e-01 2.82132106e-07 3.51047784e-05 3.04155798e-11\n",
      "  1.17346521e-09 2.06438045e-07 7.10661929e-09 2.47662455e-23\n",
      "  4.06093439e-19 1.37389307e-07 1.38717708e-26 2.43390491e-06\n",
      "  3.67592675e-12 3.93977494e-13 1.50313276e-18 7.02008183e-05]\n",
      " [7.07963090e-06 6.50358925e-06 2.46407435e-04 2.86703387e-13\n",
      "  1.70610729e-05 1.59735302e-03 6.87170043e-10 3.21280669e-09\n",
      "  2.01577688e-08 3.51575011e-07 1.74704189e-06 1.09508629e-14\n",
      "  6.10673521e-03 9.90056157e-01 9.09728369e-12 1.96062517e-03]\n",
      " [9.12006140e-01 1.56245822e-10 2.60654190e-07 5.27767442e-19\n",
      "  8.56463666e-05 2.34305389e-07 1.01830100e-03 1.60516038e-06\n",
      "  9.07811682e-06 7.88331851e-02 4.38424264e-04 1.05898914e-06\n",
      "  1.03623410e-04 1.19804566e-08 2.71899113e-03 4.78333700e-03]\n",
      " [1.19279696e-06 4.60502925e-08 9.99956250e-01 6.71408484e-11\n",
      "  6.41875204e-07 8.53077267e-07 7.06356741e-06 1.42594241e-24\n",
      "  1.59890714e-15 7.06355287e-12 3.80299519e-26 5.86483570e-11\n",
      "  2.49168352e-05 1.13965136e-07 1.89677442e-21 9.00402574e-06]\n",
      " [8.45559384e-07 9.99933600e-01 1.22163567e-06 2.25280732e-13\n",
      "  5.14162990e-10 4.65224215e-09 1.04858495e-08 2.59239277e-16\n",
      "  6.26812454e-17 4.29673019e-10 1.76424046e-16 2.07299927e-19\n",
      "  6.43664171e-05 1.56404917e-10 2.86284776e-12 2.39628117e-09]\n",
      " [9.13653970e-01 9.02717232e-15 6.44152396e-06 4.69751386e-15\n",
      "  1.30907949e-06 1.51278485e-07 1.80353620e-03 2.98881857e-03\n",
      "  4.73703898e-04 2.37289872e-02 4.75177512e-06 7.40799987e-06\n",
      "  3.14830184e-09 4.72377113e-04 2.41443688e-11 5.68585545e-02]\n",
      " [6.63963476e-07 3.63088725e-06 9.99992251e-01 6.59806915e-07\n",
      "  2.35295062e-07 8.90319427e-07 6.04660311e-13 3.49224874e-29\n",
      "  7.89940382e-23 1.35049318e-12 5.90108594e-27 5.15614366e-17\n",
      "  1.71456668e-06 9.77564807e-10 6.74458772e-16 4.70951944e-10]\n",
      " [2.19818158e-03 3.09974303e-11 1.12643371e-04 3.26737069e-21\n",
      "  4.22983896e-04 2.91119832e-05 1.25984883e-07 1.29082226e-04\n",
      "  2.69601308e-03 8.35453818e-07 8.02831709e-01 2.04719466e-12\n",
      "  1.62704185e-01 3.03586889e-09 7.57036905e-05 2.87995245e-02]\n",
      " [9.99009848e-01 4.02611659e-06 6.39020582e-04 1.48476426e-10\n",
      "  5.33037529e-14 1.88291006e-13 4.22470691e-07 2.22028337e-31\n",
      "  6.75847745e-24 2.18455281e-08 0.00000000e+00 4.53331133e-08\n",
      "  2.53838506e-10 5.15341346e-11 3.78472112e-22 3.46585090e-04]\n",
      " [3.79834564e-05 2.37671658e-03 8.37121297e-06 8.73764714e-15\n",
      "  3.96544965e-05 3.01757055e-08 5.98896258e-13 3.46737531e-13\n",
      "  5.00668187e-11 1.64645627e-07 5.87088152e-07 7.73132446e-16\n",
      "  1.65973524e-05 9.97519910e-01 7.21923021e-10 2.53251264e-09]\n",
      " [3.67928371e-02 1.01395102e-07 1.15824405e-04 4.50763066e-10\n",
      "  5.48010030e-06 5.06530151e-10 1.36438621e-11 1.21230699e-19\n",
      "  2.52075321e-08 4.33832072e-02 1.13865043e-23 7.31692051e-12\n",
      "  1.18803795e-12 1.87048134e-14 1.62763259e-04 9.19539750e-01]\n",
      " [2.32725029e-06 6.20302121e-09 9.99952555e-01 2.70958233e-14\n",
      "  1.50902423e-07 1.95493334e-13 2.69879386e-09 6.18748135e-28\n",
      "  1.10221880e-10 7.11122550e-10 2.44494342e-23 1.60170373e-07\n",
      "  2.80762433e-05 1.49386087e-05 5.93156167e-14 1.80907978e-06]\n",
      " [6.41829558e-07 9.98561442e-01 6.34846458e-07 4.52875937e-13\n",
      "  5.38926903e-09 2.13237639e-11 3.96083770e-08 1.44149031e-26\n",
      "  2.17071433e-17 1.30623637e-10 1.88922930e-28 9.64092955e-13\n",
      "  1.42264180e-03 4.01050269e-11 7.59941189e-15 1.46516004e-05]\n",
      " [8.40871751e-01 9.30083832e-09 7.90106691e-03 1.13283356e-08\n",
      "  4.48668243e-06 7.65888402e-08 5.95263031e-04 6.88278434e-10\n",
      "  1.64683183e-06 8.88256542e-03 5.82112752e-16 1.26519658e-13\n",
      "  9.36453333e-08 4.59400712e-11 2.69306821e-12 1.41743049e-01]]\n",
      "[13  9  2 12  9  2 10  0 13  9  2  1  9  2 10  0 13  0  2  1  0  2 10  0\n",
      " 13 15  2  1  0]\n",
      "[13  9  2 12  9  2 10  0 13  9  2  1  9  2 10  0 13  0  2  1  0  2 10  0\n",
      " 13 15  2  1  0]\n"
     ]
    }
   ],
   "source": [
    "nn=model.predict(trainX[1:30])\n",
    "print('ll',nn)\n",
    "nn2=numpy.argmax(nn,1)\n",
    "print(nn2)\n",
    "print(trainY[1:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
